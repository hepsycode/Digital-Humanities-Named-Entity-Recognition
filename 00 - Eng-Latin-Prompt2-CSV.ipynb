{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3442813c-26c6-4dfe-bea1-26f747d7cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.llms import Ollama\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.tools.base import Tool  \n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5efa4f65-73ba-4653-814d-2e9224ad1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONFIG ###################\n",
    "\n",
    "# Load configuration from JSON (mistral, openai, ollama, anthropic, google)\n",
    "CONFIG_FILE = \"config-no-API-key/llm_config_openai.json\"\n",
    "MODELS_FILE = \"config-no-API-key/llm_models.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "19065402-2373-4547-bc70-4f25a627864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### FUNCTIONS ##########\n",
    "def load_config(config_file):\n",
    "    try:\n",
    "        with open(config_file, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Configuration file {config_file} not found.\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return {}\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Estrae e restituisce il testo dal file PDF specificato.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'estrazione del testo da {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def save_to_file(file_path, content):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "def save_metadata(file_path, metadata):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(metadata, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "19b1a745-1b48-4e98-8cd8-97683c0e5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "config = load_config(CONFIG_FILE)\n",
    "models_config = load_config(MODELS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "60ad0161-c683-4db8-9dce-aa813417c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parameters from configuration\n",
    "LLM = config.get(\"llm\")\n",
    "if not LLM:\n",
    "    raise ValueError(\"LLM name must be specified in the configuration file.\")\n",
    "\n",
    "PRICE_PER_INPUT_TOKEN = config.get(\"price_per_input_token\")\n",
    "PRICE_PER_OUTPUT_TOKEN = config.get(\"price_per_output_token\")\n",
    "temperature = config.get(\"temperature\")\n",
    "max_retries = config.get(\"max_retries\")\n",
    "api_key = config.get(\"api_keys\", {}).get(LLM.lower(), None)\n",
    "base_url = config.get(\"base_url\")\n",
    "\n",
    "# Get model configuration\n",
    "LLM_TYPE = 'Other'\n",
    "llm_config = models_config.get(LLM, None)\n",
    "if llm_config and LLM_TYPE != 'Ollama':\n",
    "    # Update parameters dynamically\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"max_retries\"] = max_retries\n",
    "    llm_params[\"api_key\"] = api_key\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM  # Use LLM directly as the model name\n",
    "elif LLM_TYPE == 'Ollama':\n",
    "    llm_params = llm_config.get(\"params\", {})\n",
    "    llm_params[\"temperature\"] = temperature\n",
    "    llm_params[\"base_url\"] = base_url\n",
    "\n",
    "    # Initialize LLM\n",
    "    llm_class = eval(llm_config[\"class\"])\n",
    "    llm_LangChain = llm_class(**llm_params)\n",
    "    model_name = LLM  # Use LLM directly as the model name\n",
    "else:\n",
    "    raise ValueError(f\"Model configuration for '{LLM}' not found in {MODELS_FILE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a6e59194-16d8-43fd-8c77-81db1f3221fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc\\doc11.pdf\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7\\doc11.pdf.csv\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\\doc11.pdf.json\n",
      "input_variables=['english_text', 'latin_text'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Sei un assistente esperto in Named Entity Recognition e analisi testuale, con una profonda conoscenza delle lingue moderna e latina.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['english_text', 'latin_text'], input_types={}, partial_variables={}, template=\"Context:\\nI due testi che sto per farti analizzare sono uguali. Uno in lingua inglese e uno in lingua latina.\\n\\nTesto in inglese: {english_text}Testo in latino: {latin_text}Task:\\nEsegui named entity recognition ed estrapola anche i luoghi intesi come borghi, navi, carceri, mercati e luoghi similari.\\n    Estrapola anche oggetti.\\n    Inoltre, crea un file CSV in cui:\\n    - La prima colonna contenga il nome dell'entity.\\n    - La seconda colonna contenga il nome esatto ricavato dal testo latino.\\n    - La terza colonna contenga la categoria di entity, che può essere 'person', 'place' o 'physical object'.\\n    - La quarta colonna contenga il ruolo dell'entity all'interno del documento.\\n    \\n    Le istruzioni aggiuntive sono le seguenti:\\n    - Se l'entity è una persona, includi il lavoro e i legami famigliari con altri soggetti menzionati nel documento.\\n    - Se l'entity è un luogo, specifica la funzione che quel luogo ha nel contesto del documento.\\n    - Se l'entity è un oggetto, specifica la funzione che quell'oggetto ha nel contesto del documento.\\n    \\n    L'output deve contenere esclusivamente le informazioni richieste formattate in modo da poterle salvare come file CSV.\\n\\n\"), additional_kwargs={})]\n",
      "content=\"```csv\\nEntity,Name in Latin,Category,Role\\nGiano Campofregoso,lanus de Campofregoso,person,Doge of Genoa\\nDomenico Colombo,Dominicus de Columbo,person,Appointed as keeper of the Olivella gate and tower\\nAntonino Colombo,Antoninus de Colombo,person,Brother of Domenichino, involved in dowry payment\\nDomenichino Colombo,Domenighinus de Colombo,person,Brother of Antonino, involved in dowry payment\\nPasquale Frittalo,Pasquali de Fritalo,person,Recipient of the dowry payment\\nBattistina Colombo,Batestine,person,Sister of Antonino and Domenichino, wife of Giovanni Frittalo\\nGiovanni Frittalo,Iohannis de Fritalo,person,Husband of Battistina, son of Pasquale\\nGenoa,lanue,place,Location of the document's enactment\\nQuinto,ville Quinti,place,Village where the Colombos and Frittalo reside\\nOlivella gate and tower,porte Olivele,place,Structure Domenico Colombo is appointed to oversee\\nsixty lire di genovini,libras sexaginta lanue,physical object,Monetary part of dowry payment\\nsix silver spoons,coclearia sex argenti,physical object,Part of dowry payment\\nSt. Michael's Day,Sancti Michaelis,place,Deadline for partial payment\\nChristmas,Nativitatis Domini,place,Beginning of payment period\\nAngelo di Negro's house,domo Angeli de Nigro,place,Place where the document was enacted\\nBartolomeo from Terrarossa,Bartholomeo de Terrarubea,person,Witness to the document\\nBartolomeo Riccio,Bartholomeo Ricio,person,Notary and witness to the document\\nGiorgio Clavarino,Georgio Clavarino,person,Witness to the document\\n```\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 427, 'prompt_tokens': 3030, 'total_tokens': 3457, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None} id='run-8f15ad95-8adf-4c29-9953-d6c027e1b7cc-0' usage_metadata={'input_tokens': 3030, 'output_tokens': 427, 'total_tokens': 3457, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: doc\\doc11.pdf\n",
      "Results saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7\n",
      "Metadata saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\n",
      "doc\\doc49.pdf\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7\\doc49.pdf.csv\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\\doc49.pdf.json\n",
      "input_variables=['english_text', 'latin_text'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Sei un assistente esperto in Named Entity Recognition e analisi testuale, con una profonda conoscenza delle lingue moderna e latina.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['english_text', 'latin_text'], input_types={}, partial_variables={}, template=\"Context:\\nI due testi che sto per farti analizzare sono uguali. Uno in lingua inglese e uno in lingua latina.\\n\\nTesto in inglese: {english_text}Testo in latino: {latin_text}Task:\\nEsegui named entity recognition ed estrapola anche i luoghi intesi come borghi, navi, carceri, mercati e luoghi similari.\\n    Estrapola anche oggetti.\\n    Inoltre, crea un file CSV in cui:\\n    - La prima colonna contenga il nome dell'entity.\\n    - La seconda colonna contenga il nome esatto ricavato dal testo latino.\\n    - La terza colonna contenga la categoria di entity, che può essere 'person', 'place' o 'physical object'.\\n    - La quarta colonna contenga il ruolo dell'entity all'interno del documento.\\n    \\n    Le istruzioni aggiuntive sono le seguenti:\\n    - Se l'entity è una persona, includi il lavoro e i legami famigliari con altri soggetti menzionati nel documento.\\n    - Se l'entity è un luogo, specifica la funzione che quel luogo ha nel contesto del documento.\\n    - Se l'entity è un oggetto, specifica la funzione che quell'oggetto ha nel contesto del documento.\\n    \\n    L'output deve contenere esclusivamente le informazioni richieste formattate in modo da poterle salvare come file CSV.\\n\\n\"), additional_kwargs={})]\n",
      "content='```csv\\nname,latin_name,category,role\\nGiovanni Colombo,Iohannes de Columbo,person,Debtor, son of the deceased Luca from Moconesi\\nPasquale Piaggia,Pasqualis de Plazia,person,Creditor, brother of Michele, son of Oberto from Zoagli, artisan and inhabitant of Genoa\\nMichele Piaggia,Michaelis de Plazia,person,Creditor, brother of Pasquale, son of Oberto from Zoagli, artisan and inhabitant of Genoa\\nOberto Piaggia,Oberti,person,Ancestor, father of Pasquale and Michele\\nBenedetto Colombo,Benedictus de Columbo,person,Creditor, brother of Giovanni, weaver of woolen cloth\\nAntonio Leverone,Antonio de Leverono,person,Proxy, acted as proxy for Giovanni Colombo\\nCristoforo Sisto,Cristofori Sixti,person,Notary, public document writer\\nPietro Rimassa,Petrus Roymacia,person,Ancestor, father of Appolonia, baker\\nAppolonia,Apolonie,person,Deceased, daughter of Pietro Rimassa, wife of deceased Tommaso\\nBenedetto Dezerga,Benedictus de Dezerega,person,First Buyer, first buyer of the house from Tommaso Piaggia\\nDomenico Colombo,Dominicus de Columbo,person,Debtor, cheesemonger, son of the deceased Giovanni\\nGerolamo delle Vigne,Ieronimo de Vineis,person,Creditor, cheesemonger, son of the deceased Lanfranco\\nMariola,Mariola,person,Heir, daughter of Pietro Rimassa, wife of Pasquale\\nTommaso Piaggia,Thome,person,Deceased, brother of Pasquale and Michele, former owner of the house\\nMargarita,Margaritam,person,Deceased, mother of Pasquale and Michele, wife of Oberto\\nPietro,Petrus,person,Ancestor, father of Mariola\\nBorgo Santo Stefano,burgo Sancti Stephani,place,Location of event, in the district of Portoria, Genoa\\nPortoria,Porta Aurea,place,Encumbered Property, district in Genoa where the house is located\\nOlivella,Olivelle,place,Property Sale, district in Genoa where the house was sold\\nGenoa,Ianue,place,City, location of all events\\ncarrugia,carrubeus,place,Boundary, front boundary of the house in Portoria\\nquintana,quintana,place,Boundary, behind boundary of the house in Portoria\\nlire di genovini,libras ianuinorum,physical object,Currency, used for transactions and debts\\nhouse,domus,physical object,Encumbered Property, sold and mortgaged property in Genoa\\ndowry,dotis,physical object,Legal Claim, provided by Pietro Rimassa for Appolonia\\n```\\n' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 640, 'prompt_tokens': 7202, 'total_tokens': 7842, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None} id='run-8765c81f-05f2-4817-b83a-38823582bcdd-0' usage_metadata={'input_tokens': 7202, 'output_tokens': 640, 'total_tokens': 7842, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: doc\\doc49.pdf\n",
      "Results saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7\n",
      "Metadata saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\n",
      "doc\\doc6.pdf\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7\\doc6.pdf.csv\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\\doc6.pdf.json\n",
      "input_variables=['english_text', 'latin_text'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Sei un assistente esperto in Named Entity Recognition e analisi testuale, con una profonda conoscenza delle lingue moderna e latina.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['english_text', 'latin_text'], input_types={}, partial_variables={}, template=\"Context:\\nI due testi che sto per farti analizzare sono uguali. Uno in lingua inglese e uno in lingua latina.\\n\\nTesto in inglese: {english_text}Testo in latino: {latin_text}Task:\\nEsegui named entity recognition ed estrapola anche i luoghi intesi come borghi, navi, carceri, mercati e luoghi similari.\\n    Estrapola anche oggetti.\\n    Inoltre, crea un file CSV in cui:\\n    - La prima colonna contenga il nome dell'entity.\\n    - La seconda colonna contenga il nome esatto ricavato dal testo latino.\\n    - La terza colonna contenga la categoria di entity, che può essere 'person', 'place' o 'physical object'.\\n    - La quarta colonna contenga il ruolo dell'entity all'interno del documento.\\n    \\n    Le istruzioni aggiuntive sono le seguenti:\\n    - Se l'entity è una persona, includi il lavoro e i legami famigliari con altri soggetti menzionati nel documento.\\n    - Se l'entity è un luogo, specifica la funzione che quel luogo ha nel contesto del documento.\\n    - Se l'entity è un oggetto, specifica la funzione che quell'oggetto ha nel contesto del documento.\\n    \\n    L'output deve contenere esclusivamente le informazioni richieste formattate in modo da poterle salvare come file CSV.\\n\\n\"), additional_kwargs={})]\n",
      "content='```plaintext\\nEntity Name,Latin Name,Category,Role\\nGuglielmo di Triclino,Gulielmo de Triclino,person,witness\\nAntonio Ratto di Monterosato,Antonio Ratto de Monterosato,person,witness\\nSimone di Mongiardino,Simone de Mongiardino,person,witness\\nPietro Ghirardetto,Petrus de Guiratdeto,person,debtor\\nAntonio Musante,Antonio de Muzante,person,creditor\\nLodisio of Pavia,Lodixio de Papia,person,wool-worker and witness\\nBorgo Santo Stefano,Burgo Sancti Stephani,place,location of the legal act\\nQuinto,Quinti,place,residence of involved parties\\nBisagno,Bisamnis,place,jurisdiction\\nDomenico of Terrarossa,Dominicus de Terra Rubea,person,land seller\\nBenedetto of Moconesi,Benedictus de Moconexi,person,land buyer\\nAntonio Bagnara,Antonio de Bagneria,person,land boundary owner\\nStefano Besaccia,Stephanus Bezacie,person,land boundary owner\\nDeserino Garro,Dexerini Garri,person,land boundary owner\\nFasciole,Fassiole,place,location of the land\\nchestnut trees and meadow,castaneate et prative,physical object,features of sold land\\nJacobo Mazurro,Iacobo Mazurro,person,witness\\nPietro Antonio Narixe,Petro Antonio Narixe,person,witness\\nMattheus de Flisco,Mattheus de Flisco,person,noble and procurator\\nGeorgius,Georgii,person,cardinal\\nMonastery of San Stefano,monasterii Sancti Stephani,place,land owner\\nDominighino Columbo,Dominighino Columbo,person,tenant\\nIoannis,Ioannis,person,father of Dominighino Columbo\\nPetri de Croza,Petri de Croza,person,neighbor\\nBertore de Valetariis,Bertore de Valetariis,person,neighbor\\nRaffus de Gravano,Raffus de Gravano,person,former tenant\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 478, 'prompt_tokens': 2850, 'total_tokens': 3328, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None} id='run-7f750322-8164-420d-b3e7-eb002dd71cae-0' usage_metadata={'input_tokens': 2850, 'output_tokens': 478, 'total_tokens': 3328, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: doc\\doc6.pdf\n",
      "Results saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7\n",
      "Metadata saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\n",
      "doc\\doc75.pdf\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7\\doc75.pdf.csv\n",
      "Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\\doc75.pdf.json\n",
      "input_variables=['english_text', 'latin_text'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Sei un assistente esperto in Named Entity Recognition e analisi testuale, con una profonda conoscenza delle lingue moderna e latina.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['english_text', 'latin_text'], input_types={}, partial_variables={}, template=\"Context:\\nI due testi che sto per farti analizzare sono uguali. Uno in lingua inglese e uno in lingua latina.\\n\\nTesto in inglese: {english_text}Testo in latino: {latin_text}Task:\\nEsegui named entity recognition ed estrapola anche i luoghi intesi come borghi, navi, carceri, mercati e luoghi similari.\\n    Estrapola anche oggetti.\\n    Inoltre, crea un file CSV in cui:\\n    - La prima colonna contenga il nome dell'entity.\\n    - La seconda colonna contenga il nome esatto ricavato dal testo latino.\\n    - La terza colonna contenga la categoria di entity, che può essere 'person', 'place' o 'physical object'.\\n    - La quarta colonna contenga il ruolo dell'entity all'interno del documento.\\n    \\n    Le istruzioni aggiuntive sono le seguenti:\\n    - Se l'entity è una persona, includi il lavoro e i legami famigliari con altri soggetti menzionati nel documento.\\n    - Se l'entity è un luogo, specifica la funzione che quel luogo ha nel contesto del documento.\\n    - Se l'entity è un oggetto, specifica la funzione che quell'oggetto ha nel contesto del documento.\\n    \\n    L'output deve contenere esclusivamente le informazioni richieste formattate in modo da poterle salvare come file CSV.\\n\\n\"), additional_kwargs={})]\n",
      "content=\"```csv\\nEntity Name,Entity Name (Latin),Entity Category,Role\\nDomenico Colombo,Dominicus de Columbo,person,weaver of woolen cloth, husband of Susanna\\nSusanna Fontanarossa,Susanna,person,wife of Domenico Colombo, involved in property transaction\\nGiuliano Caprile,Giulianus,person,buyer of lands from Domenico Colombo\\nStampino Caprile,Stampinus,person,buyer of lands from Domenico Colombo\\nGoagnino Fontanarossa,Goagninus,person,protester of property transaction\\nPietro Fazio,Petrus,person,notary involved in property transaction\\nGenoa,Ianua,place,location where legal documents were executed\\nFossatello,Fossatello,place,area in Genoa where the notary's bench was located\\nSanto Stefano Monastery,Sancti Stephani,place,location where guild regulations were established\\nSilk Cloth,Textorum pannorum lane,physical object,object of apprenticeship and guild regulation\\nWoolen Cloth,Pannorum lane,physical object,object of guild regulation\\nHoly Gospels,Sacra Evangelia,physical object,object on which oaths were sworn\\n```\\n\\nThis CSV output captures the requested named entities, their corresponding Latin names, categories, and roles in the context of the documents.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 286, 'prompt_tokens': 4848, 'total_tokens': 5134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None} id='run-97653937-89ea-4df1-a05c-8afc68b32fcf-0' usage_metadata={'input_tokens': 4848, 'output_tokens': 286, 'total_tokens': 5134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Processed: doc\\doc75.pdf\n",
      "Results saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7\n",
      "Metadata saved to: Prompt2-Results-gpt-4o-2024-08-06-0.7/JSON\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "\n",
    "# Few-shot context\n",
    "context = (\n",
    "    \"I due testi che sto per farti analizzare sono uguali. Uno in lingua inglese e uno in lingua latina.\"\n",
    ")\n",
    "\n",
    "task = (\n",
    "    f\"\"\"Esegui named entity recognition ed estrapola anche i luoghi intesi come borghi, navi, carceri, mercati e luoghi similari.\n",
    "    Estrapola anche oggetti.\n",
    "    Inoltre, crea un file CSV in cui:\n",
    "    - La prima colonna contenga il nome dell'entity.\n",
    "    - La seconda colonna contenga il nome esatto ricavato dal testo latino.\n",
    "    - La terza colonna contenga la categoria di entity, che può essere 'person', 'place' o 'physical object'.\n",
    "    - La quarta colonna contenga il ruolo dell'entity all'interno del documento.\n",
    "    \n",
    "    Le istruzioni aggiuntive sono le seguenti:\n",
    "    - Se l'entity è una persona, includi il lavoro e i legami famigliari con altri soggetti menzionati nel documento.\n",
    "    - Se l'entity è un luogo, specifica la funzione che quel luogo ha nel contesto del documento.\n",
    "    - Se l'entity è un oggetto, specifica la funzione che quell'oggetto ha nel contesto del documento.\n",
    "    \n",
    "    L'output deve contenere esclusivamente le informazioni richieste formattate in modo da poterle salvare come file CSV.\"\"\"\n",
    ")\n",
    "\n",
    "base_output_dir = f\"Prompt2-Results-{model_name.lower()}-{temperature}\"\n",
    "base_output_json_dir = f\"Prompt2-Results-{model_name.lower()}-{temperature}/JSON\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "os.makedirs(base_output_json_dir, exist_ok=True)\n",
    "    \n",
    "# Specifica la cartella in cui cercare i file PDF\n",
    "folder_path = \"doc\"  # <-- Sostituisci con il percorso corretto\n",
    "\n",
    "# Dizionario per salvare le coppie di file: la chiave è il nome base, \n",
    "# e il valore è un dizionario con le chiavi 'english' e 'latin'\n",
    "pairs = {}\n",
    "\n",
    "# Scorri tutti i file nella cartella\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.lower().endswith(\".pdf\"):\n",
    "        # Se il file termina con \"latino.pdf\" è la versione in latino\n",
    "        if file.lower().endswith(\"latino.pdf\"):\n",
    "            # Rimuovo gli ultimi 10 caratteri (\"latino.pdf\") per ottenere il nome base\n",
    "            base_name = file[:-10]\n",
    "            if base_name not in pairs:\n",
    "                pairs[base_name] = {}\n",
    "            pairs[base_name]['latin'] = os.path.join(folder_path, file)\n",
    "        else:\n",
    "            # Altrimenti, supponiamo sia la versione in inglese: rimuovo \".pdf\"\n",
    "            base_name = file[:-4]\n",
    "            if base_name not in pairs:\n",
    "                pairs[base_name] = {}\n",
    "            pairs[base_name]['english'] = os.path.join(folder_path, file)\n",
    "\n",
    "for base, files in pairs.items():\n",
    "    # Verifica che esista la coppia (versione in inglese e versione in latino)\n",
    "    if 'english' in files and 'latin' in files:\n",
    "        english_text = extract_text_from_pdf(files['english'])\n",
    "        latin_text   = extract_text_from_pdf(files['latin'])\n",
    "\n",
    "        print(files['english'])\n",
    "\n",
    "        ############ Save file ##########\n",
    "        output_res_path = os.path.join(base_output_dir, os.path.basename(files['english']) + '.csv')\n",
    "        print(output_res_path)\n",
    "        metadata_path = os.path.join(base_output_json_dir, os.path.basename(files['english']) + '.json')\n",
    "        print(metadata_path)\n",
    "\n",
    "        ####################### Synthetic Modeling Operation ###########################\n",
    "        # Chat few-shot prompt template\n",
    "        chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", \"Sei un assistente esperto in Named Entity Recognition e analisi testuale, con una profonda conoscenza delle lingue moderna e latina.\"),\n",
    "                (\n",
    "                    \"user\",\n",
    "                    f\"Context:\\n{context}\\n\\n\"\n",
    "                    \"Testo in inglese: {english_text}\"\n",
    "                    \"Testo in latino: {latin_text}\"\n",
    "                    f\"Task:\\n{task}\\n\\n\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(chat_prompt)\n",
    "\n",
    "        # Start timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Invoke the model\n",
    "        response = chat_prompt | llm_LangChain\n",
    "        result = response.invoke(\n",
    "            {\n",
    "                \"english_text\": english_text,\n",
    "                \"latin_text\": latin_text\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Stop timer\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time  # Prompt Execution Time (in second)\n",
    "\n",
    "        if LLM_TYPE != 'Ollama':\n",
    "            output_res = result.content.strip()\n",
    "        else:\n",
    "            output_res = result.strip()\n",
    "        print(result)\n",
    "        \n",
    "        if LLM_TYPE != 'Ollama':\n",
    "            metadata = {\n",
    "                \"response_length\": len(output_res),\n",
    "                \"execution_time\": execution_time,\n",
    "                \"temperature\": temperature,\n",
    "                \"usage\": result.usage_metadata,\n",
    "                \"price_usd\": result.usage_metadata.get(\"input_tokens\", 0) * PRICE_PER_INPUT_TOKEN + result.usage_metadata.get(\"output_tokens\", 0) * PRICE_PER_OUTPUT_TOKEN,\n",
    "                \"model_name\": model_name\n",
    "            }\n",
    "        else:\n",
    "            metadata = {\n",
    "                \"response_length\": len(output_res),\n",
    "                \"execution_time\": execution_time,\n",
    "                \"temperature\": temperature,\n",
    "                \"model_name\": model_name\n",
    "            }\n",
    "\n",
    "        save_to_file(output_res_path, output_res)\n",
    "        save_metadata(metadata_path, metadata)\n",
    "\n",
    "        print(f\"Processed: {files['english']}\")\n",
    "        print(f\"Results saved to: {base_output_dir}\")\n",
    "        print(f\"Metadata saved to: {base_output_json_dir}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Attenzione: La coppia per '{base}' non è completa. File trovati: {list(files.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e35f5-2539-4935-9069-5ba6fd89d949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
